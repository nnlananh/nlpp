{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "064c8cb3",
   "metadata": {},
   "source": [
    "Import vader sentiment library. When downloading models from nltk, note that the directory should be named as \"nltk_data\", otherwise, using SentimentIntensityAnalyzer will return an error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "017e9dd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "showing info https://raw.githubusercontent.com/nltk/nltk_data/gh-pages/index.xml\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package vader_lexicon to E:/nltk...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to E:/nltk...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize, RegexpTokenizer\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "nltk.download(download_dir=\"E:/nltk_data\")\n",
    "nltk.download('vader_lexicon', download_dir=\"E:/nltk\")\n",
    "nltk.download('punkt', download_dir=\"E:/nltk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7656d791",
   "metadata": {},
   "source": [
    "We will test the SentimentIntensityAnalyzer class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d8a48d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'the': 0.00 (Neutral)\n",
      "'movie': 0.00 (Neutral)\n",
      "'was': 0.00 (Neutral)\n",
      "'incredibly': 0.00 (Neutral)\n",
      "'exciting': 0.49 (Positive)\n",
      "'but': 0.00 (Neutral)\n",
      "'also': 0.00 (Neutral)\n",
      "'slightly': 0.00 (Neutral)\n",
      "'disappointing': -0.49 (Negative)\n",
      "'on': 0.00 (Neutral)\n",
      "'other': 0.00 (Neutral)\n",
      "'hand': 0.49 (Positive)\n",
      "'we': 0.00 (Neutral)\n",
      "'have': 0.00 (Neutral)\n",
      "'a': 0.00 (Neutral)\n",
      "'better': 0.44 (Positive)\n",
      "'choice': 0.00 (Neutral)\n"
     ]
    }
   ],
   "source": [
    "def analyze_word_sentiment(sentence):\n",
    "    # words = word_tokenize(sentence)\n",
    "\n",
    "    analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "\n",
    "    words = tokenizer.tokenize(sentence.lower())\n",
    "\n",
    "    word_sentiments = {word: analyzer.polarity_scores(word)[\"compound\"] for word in words}\n",
    "\n",
    "    return word_sentiments\n",
    "\n",
    "sentence = \"The movie was incredibly exciting but also slightly disappointing. On the other hand, we have a better choice.\"\n",
    "\n",
    "word_sentiment_scores = analyze_word_sentiment(sentence)\n",
    "\n",
    "for word, score in word_sentiment_scores.items():\n",
    "    sentiment = \"Positive\" if score > 0 else \"Negative\" if score < 0 else \"Neutral\"\n",
    "\n",
    "    print(f\"'{word}': {score:.2f} ({sentiment})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3e5ac982",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5ForConditionalGeneration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fba1e5a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using the default legacy behaviour of the <class 'transformers.models.t5.tokenization_t5.T5Tokenizer'>. This is expected, and simply means that the `legacy` (previous) behavior will be used so nothing changes for you. If you want to use the new behaviour, set `legacy=False`. This should only be set if you understand what it means, and thoroughly read the reason why this was added as explained in https://github.com/huggingface/transformers/pull/24565\n"
     ]
    }
   ],
   "source": [
    "model_name = \"t5-small\"\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)\n",
    "model = T5ForConditionalGeneration.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ab947c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[12198,  1635,  1737,     8,  7142,    10,    71,  7538,    53,  1437,\n",
      "            19,     3,     9, 18913,   825,    13, 29761,     3, 16012,    46,\n",
      "          9838,  1437,    24, 23307,     7, 13619,    30,     3,     9,  7706,\n",
      "            13,  4874,  1315,    12,     3,     9,   953,    13,  2219,     5,\n",
      "             3,  4868,     8,   825,    31,     7, 16538,     6,    34,    19,\n",
      "          3919,    13,     3, 10311,   136,  1218, 12628,     5,     1]])\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"\n",
    "A Turing machine is a mathematical model of computation describing an abstract machine\n",
    "that manipulates symbols on a strip of tape according to a table of rules. Despite the\n",
    "model's simplicity, it is capable of implementing any computer algorithm.\n",
    "\"\"\"\n",
    "\n",
    "input_text = \"Summarize the sentence: \" + text\n",
    "input_ids = tokenizer.encode(input_text, return_tensors=\"pt\", max_length=400, truncation=True)\n",
    "\n",
    "print(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a0c37c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
